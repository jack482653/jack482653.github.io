<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
        <title>Xian&#39;s note</title>
        <description>Xian&#39;s note - 張 伍賢</description>
        <link>http://jack482653.github.io</link>
        <atom:link href="http://jack482653.github.io/rss.xml" rel="self" type="application/rss+xml" />
        <lastBuildDate>Wed, 21 Oct 2015 17:27:34 +0800</lastBuildDate>
        <pubDate>Wed, 21 Oct 2015 17:27:34 +0800</pubDate>
        <ttl>60</ttl>


        <item>
                <title>Data Clustering</title>
                <description>
&lt;p&gt;原文多達60頁，所以我暫時挑我想看，之後再慢慢把它看完。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2 id=&quot;clustering-techniques&quot;&gt;Clustering Techniques&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/Data Clustering/A taxonomy of clustering approaches.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;hierarchical（階層式）&lt;/th&gt;
      &lt;th&gt;partitional（分割式）&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Produce a nested series of partitions.&lt;/td&gt;
      &lt;td&gt;Produce only one partition.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;section&quot;&gt;用不同面向去觀察分群演算法&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;根據演算法結構和運算方式
    &lt;ul&gt;
      &lt;li&gt;Agglomerative（聚合式）
        &lt;ul&gt;
          &lt;li&gt;從每一個點視為一個 cluster 開始不斷合併。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;divisive
        &lt;ul&gt;
          &lt;li&gt;所有點視為一個 cluster，慢慢切成多個 cluster。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;使用feature的方式
    &lt;ul&gt;
      &lt;li&gt;Polythetic
        &lt;ul&gt;
          &lt;li&gt;一次看所有feature（也就是所有的feature都拿去算兩個點間的距離）&lt;/li&gt;
          &lt;li&gt;大部分演算法屬於此類型&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Monothetic
        &lt;ul&gt;
          &lt;li&gt;一個一個feature看&lt;/li&gt;
          &lt;li&gt;缺點：點的維度為\(d\)，會產生\(2^d\)個群，維度很大的時候就會崩潰了。&lt;/li&gt;
          &lt;li&gt;例子
&lt;img src=&quot;/assets/Data Clustering/Monothetic partitional clustering.png&quot; alt=&quot;Monothetic partitional clustering&quot; /&gt;
            &lt;ol&gt;
              &lt;li&gt;根據 feature \(X_1\)，找到一直線\(V\)，分割出1、2和3、4兩塊。&lt;/li&gt;
              &lt;li&gt;再根據 feature \(X_2\)，找到兩直線\(H_1\)和\(H_2\)，分成1、2、3、4共四塊。&lt;/li&gt;
            &lt;/ol&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Hard vs Fuzzy
        &lt;ul&gt;
          &lt;li&gt;Hard
            &lt;ul&gt;
              &lt;li&gt;演算法直接分配點到一個 cluster。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Fuzzy
            &lt;ul&gt;
              &lt;li&gt;每一個點可能屬於一個或多個 cluster。&lt;/li&gt;
              &lt;li&gt;演算法計算點屬於哪一群的可能性。&lt;/li&gt;
              &lt;li&gt;取可能性最大的群加入 -&amp;gt; 退化成Hard。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;最佳化 error function（下的標題很奇怪）
        &lt;ul&gt;
          &lt;li&gt;Deterministic
            &lt;ul&gt;
              &lt;li&gt;Given a dataset, always arrive at the same clustering.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;Stochastic
            &lt;ul&gt;
              &lt;li&gt;有些參數是隨機的，因此每次結果可能不一樣。&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Incremental vs Non-incremental
        &lt;ul&gt;
          &lt;li&gt;dataset 大小、執行時間或記憶體空間的限制&lt;/li&gt;
          &lt;li&gt;或是 data stream，需要逐步更新&lt;/li&gt;
          &lt;li&gt;因此分群演算法設計上必須減少
            &lt;ul&gt;
              &lt;li&gt;掃過整個 dataset 的次數&lt;/li&gt;
              &lt;li&gt;運算過程中 data point 被用到的次數&lt;/li&gt;
              &lt;li&gt;演算法的操作中所使用的資料結構大小&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hierarchical-clustering-algorithms&quot;&gt;Hierarchical Clustering Algorithms&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/Data Clustering/The dendrogram obtained using the single-link algorithm.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;產生X軸表資料點，Y軸表相似度的樹狀圖。相似度越小，群的數量越多，群內的資料點也越少。&lt;/li&gt;
  &lt;li&gt;三大類型
    &lt;ul&gt;
      &lt;li&gt;Single-Link
        &lt;ul&gt;
          &lt;li&gt;兩群的相似性：\( distance(C_1, C_2) = min \text{ } distance(a, b) \text{, } \forall a \in C_1 \text{, } b \in C_2 \)&lt;/li&gt;
          &lt;li&gt;Chaining effect: a tendency to produce clusters that are straggly or elongated.&lt;/li&gt;
          &lt;li&gt;有辦法分開同心圓的資料。&lt;/li&gt;
        &lt;/ul&gt;

        &lt;p&gt;&lt;img src=&quot;/assets/Data Clustering/Two concentric clusters.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;Complete-Link
        &lt;ul&gt;
          &lt;li&gt;兩群的相似性：\( distance(C_1, C_2) = max \text{ } distance(a, b) \text{, } \forall a \in C_1 \text{, } b \in C_2 \)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Minimum-Variance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
                <link>http://jack482653.github.io/2015/10/19/data-clustering</link>
                <guid>http://jack482653.github.io/2015/10/19/data-clustering</guid>
                <pubDate>Mon, 19 Oct 2015 00:00:00 +0800</pubDate>
        </item>

        <item>
                <title>測試 MathJax</title>
                <description>
&lt;p&gt;來測試一下MathJax的功能。&lt;/p&gt;

&lt;h1 id=&quot;section&quot;&gt;方程式&lt;/h1&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;a^2 + b^2 = c^2&lt;/script&gt;
\[ \mathbf{X} = \mathbf{Z} \mathbf{P^\mathsf{T}} \]
看起來應該OK。&lt;/p&gt;
</description>
                <link>http://jack482653.github.io/2015/10/18/-mathjax</link>
                <guid>http://jack482653.github.io/2015/10/18/-mathjax</guid>
                <pubDate>Sun, 18 Oct 2015 00:00:00 +0800</pubDate>
        </item>


</channel>
</rss>
